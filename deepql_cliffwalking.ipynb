{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/viniciusandreossi/anaconda3/envs/cleanrl/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.pyplot._IonContext at 0x7f3d7b2d7eb0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from importlib import reload\n",
    "from copy import deepcopy\n",
    "from typing import List, Dict\n",
    "from collections import deque, namedtuple\n",
    "\n",
    "import random\n",
    "import math\n",
    "\n",
    "import utils.plots_cliffwalking as plots\n",
    "from env.cliff_walking import WindyCliffWalking\n",
    "\n",
    "# set up matplotlib\n",
    "is_ipython = 'inline' in matplotlib.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display\n",
    "\n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resolvendo o ambiente Cliff Walking com Deep Q-Learning\n",
    "\n",
    "O [Cliff Walking](https://gymnasium.farama.org/environments/toy_text/cliff_walking/) será utilizado novamente para entendermos o funcionamento do Deep Q-Learning, o algoritmo mais simples de Deep Reinforcement Learning. Recapitulando o objetivo do Cliff Walking, o agente deve ser capaz de atravessar um tabuleiro do início ao fim tomando cuidado para não cair em um penhasco. Se o agente cair no penhasco, ele retorna para o início do tabuleiro e leva uma penalidade de recompensa.\n",
    "\n",
    "<img src=\"media/cliff_walking.gif\" width=\"200\">\n",
    "\n",
    "Abaixo seguem algumas informações importantes para a modelagem do ambiente como um Processo de Decisão de Markov (MDP):\n",
    "\n",
    "### Espaço de ações\n",
    "\n",
    "O espaço de ações é discreto e contém os inteiros do intervalo {0, 3}. Uma ação deve indicar a direção de um movimento:\n",
    "* 0: Cima\n",
    "* 1: Direita\n",
    "* 2: Baixo\n",
    "* 3: Esquerda\n",
    "\n",
    "### Espaço de estados\n",
    "\n",
    "O estado representa a posição do jogador no tabuleiro. Logo, o espaço de estados também é discreto e contém os inteiros do intervalo {0, 47}. O valor numérico da posição do agente no tabuleiro pode ser obtido como linha_atual * nlinhas + coluna, sendo que as linhas e colunas começam em 0.\n",
    "\n",
    "### Recompensas\n",
    "\n",
    "A cada movimento do agente uma penalidade de -1 é aplicada, a menos que o jogador caia do penhasco, o que resulta em uma penalidade -100.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criando o modelo\n",
    "\n",
    "No Deep Q-Learning, os Q-valores de cada ação associados a um estado são calculados através de uma rede neural. Ou seja, a rede neural recebe como entrada um vetor de estados e deve retornar o vetor de Q-valores onde cada elemento representa o Q-valor de uma ação. Um Q-valor pode ser interpretado como \"a recompensa acumulada total esperada por executar a ação A no estado S e depois seguir a mesma política até o final do episódio\".\n",
    "\n",
    "Por se tratar de um problema relativamente simples, o modelo para solucionar o CliffWalking pode ser uma rede MLP. Além disso, note que a predição dos Q-valores é uma tarefa de regressão, portanto não é utilizada uma função de ativação softmax no final da rede. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversão de inteiro para (x,y)\n",
    "\n",
    "A rede neural fica mais simples se receber como entrada um par (x,y) em vez de um inteiro. Se fossemos alimentá-la com um inteiro, teríamos que converter esse inteiro para um one-hot. Como são 48 estados, precisaríamos de um vetor de 48 elementos, sendo 47 elementos zerados! Ao passarmos um par (x,y), o vetor fica reduzido para apenas dois elementos. A função abaixo codifica o estado para a posição do agente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Qnet(nn.Module):\n",
    "    def __init__(self, layer_sizes: List[int] = [64, 64]):\n",
    "        super().__init__()\n",
    "\n",
    "        # construindo a rede neural\n",
    "        layers = []\n",
    "        input_size = 2 # entrada: posicao (x, y)\n",
    "        for n_neurons in layer_sizes:\n",
    "            layers.append(nn.Linear(input_size, n_neurons))\n",
    "            layers.append(nn.ReLU())\n",
    "            input_size = n_neurons\n",
    "        layers.append(nn.Linear(input_size, 4))\n",
    "        self.nn = nn.Sequential(*layers)\n",
    "\n",
    "    def _encode_state(self, state: int | torch.Tensor) -> torch.Tensor:\n",
    "        if isinstance(state, int):\n",
    "            state = torch.tensor(state, dtype=torch.float32)\n",
    "\n",
    "        x = (state % 12) / 11\n",
    "        y = (state // 12) / 3\n",
    "\n",
    "        x = x.reshape(-1, 1)\n",
    "        y = y.reshape(-1, 1)\n",
    "\n",
    "        return torch.cat([x, y], dim=-1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self._encode_state(x)\n",
    "        x = self.nn(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replay buffer\n",
    "\n",
    "Replay buffers são utilizados (...)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = namedtuple('Transition', ('state', 'action', 'reward', 'next_state', 'terminated'))\n",
    "\n",
    "class ReplayBuffer:\n",
    "    def __init__(self, capacity=1024, backup_fraction=0.1):\n",
    "        self.backup_size = int(capacity * backup_fraction)\n",
    "        self.queue_size = capacity - self.backup_size\n",
    "        self.backup = []\n",
    "        self.queue = deque([], maxlen=self.queue_size)\n",
    "        self.buffer = []\n",
    "    \n",
    "    def push(self, *args):\n",
    "        \"\"\" Save a transition into the buffer.\"\"\"\n",
    "        if len(self.backup) < self.backup_size:\n",
    "            self.backup.append(Transition(*args))\n",
    "        else:\n",
    "            self.queue.append(Transition(*args))\n",
    "        self.buffer = self.backup + list(self.queue)\n",
    "    \n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.buffer, batch_size)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.buffer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amostrando ações com a política $\\epsilon$-greedy\n",
    "\n",
    "No final do treinamento, espera-se que a melhor ação para cada estado seja aquela cujo Q-Valor é o maior. No entanto, para que o Q-Learning convirja adequadamente, é necessário que no início do treinamento o agente \"explore\" bem o ambiente. Isto é, que o agente visite um grande número de estados mesmo que não sejam necessariamente ótimos. Uma técnica amplamente utilizada para essa finalidade é a política $\\epsilon$-greedy. Ela consiste em forçar o agente a escolher ações aleatoriamente com uma frequência que diminui conforme o treinamento avança."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def get_action(model, state, epsilon, random=True, n_actions=4):\n",
    "    if torch.rand(1) < epsilon and random:\n",
    "        return torch.randint(n_actions, (1,)).item()\n",
    "    qvals = model(state)\n",
    "    return torch.argmax(qvals).item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamento da rede neural \n",
    "\n",
    "A cada passo do treinamento, o agente executará uma ação e utilizará a informação retornada pelo ambiente para calcular uma loss e atualizar seus pesos de forma a minimizá-la. A loss que será utilizada é o erro quadrático médio entre o Q-valor escolhido e o maior Q-valor do próximo estado calculado utilizando a rede com os pesos anteriores à ultima atualização:\n",
    "\n",
    "$$L_i(\\theta_i)=\\mathbb{E}[(y_i - Q(s,a;\\theta_i))^2]$$\n",
    "$$y_i=\\mathbb{E}[R(s')+\\gamma\\max_A Q(s',A;\\theta_{i-1})]$$\n",
    "\n",
    "Note que, portanto, serão necessárias duas redes neurais com a mesma arquitetura, mas uma terá os pesos deefasados em uma iteração com relação à outra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_q_net(model: Qnet, \n",
    "                 model_target: Qnet,\n",
    "                 optimizer: torch.optim.Optimizer, \n",
    "                 batch_of_transitions: List[Transition],\n",
    "                 gamma):\n",
    "    \n",
    "    # Convert a list of Transitions into a Transition of lists\n",
    "    # Check: https://stackoverflow.com/questions/19339/transpose-unzip-function-inverse-of-zip/19343#19343\n",
    "    batch = Transition(*zip(*batch_of_transitions))\n",
    "    \n",
    "    # transformando o batch de estados em um tensor\n",
    "    states = torch.tensor(batch.state)\n",
    "    actions = torch.tensor(batch.action)\n",
    "    rewards = torch.tensor(batch.reward)\n",
    "    next_states = torch.tensor(batch.next_state)\n",
    "    terminated = torch.tensor(batch.terminated)\n",
    "    \n",
    "    predictions = model(states).gather(1, actions.unsqueeze(1)).squeeze() # seleciona o qval da acao tomada\n",
    "\n",
    "    # se o estado é terminal, o valor é a recompensa\n",
    "    with torch.no_grad():\n",
    "        targets = rewards + gamma * model_target(next_states).max(-1).values * (1 - terminated.int()) # else rewards + gamma * max_a Q(s', a)\n",
    "    \n",
    "    loss = F.mse_loss(predictions, targets)\n",
    "\n",
    "    # atualizando os pesos da rede\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop de treinamento\n",
    "\n",
    "No loop de treinamento, juntaremos todas as funções desenvolvidas até o momento. A ideia principal é definir um número máximo de episódios (estágio inicial até o estágio final) para que o agente colete experiências do ambiente e otimize sua tabela de QValores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Heatmap:\n",
    "    def __init__(self, rows, cols):\n",
    "        self.heatmap = torch.zeros(rows, cols)\n",
    "    \n",
    "    def update(self, state):\n",
    "        col = state % 12\n",
    "        row = state // 12\n",
    "        self.heatmap[row][col] += 1\n",
    "\n",
    "    def clear(self):\n",
    "        self.heatmap = torch.zeros(self.heatmap.shape)\n",
    "    \n",
    "    def plot(self, episode):\n",
    "        print(self.heatmap.int())\n",
    "        plt.imshow(self.heatmap, cmap='hot', interpolation='nearest')\n",
    "        plt.title(f'Heatmap for the last 20 eps from ep {episode}')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(metrics: Dict, show_results=False):\n",
    "    rewards = torch.tensor(metrics['episode_rewards'])\n",
    "    plt.figure(1)\n",
    "    plt.clf\n",
    "    plt.title('Total reward of each episode')\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Total reward')\n",
    "    plt.plot(rewards)\n",
    "\n",
    "    # Take 100 episode averages and plot them too\n",
    "    if metrics['avg_reward'] is not None: \n",
    "        x = range(49, 49 + len(metrics['avg_reward']))\n",
    "        plt.plot(x, metrics['avg_reward'].numpy())\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "\n",
    "    # plot heatmap\n",
    "    metrics['heatmap'].plot(len(metrics['episode_rewards']))\n",
    "\n",
    "    # dump qtable\n",
    "    for i, q in enumerate(metrics['qtable']):\n",
    "        if i not in range(37, 47):\n",
    "            print(f'Q values for state {i}: {q}')\n",
    "\n",
    "    if not show_results:\n",
    "        display.display(plt.gcf())\n",
    "        display.clear_output(wait=True)\n",
    "    else:\n",
    "        display.display(plt.gcf())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "        env: gym.Env, \n",
    "        model: Qnet,\n",
    "        total_steps=1_000_000,\n",
    "        replay_buffer_size=10_000, # tamanho do replay buffer\n",
    "        batch_size=64, # tamanho do batch\n",
    "        gamma=0.99,\n",
    "        learning_rate=1e-4,\n",
    "        learning_freq=1,\n",
    "        target_update_freq=10,\n",
    "        tau=1.0,\n",
    "        epsilon_0 = 1, # probabilidade inicial de escolher uma ação aleatória\n",
    "        epsilon_f=0.05, # probabilidade final de escolher uma ação aleatória (após o decaimento)\n",
    "        epsilon_decay = 10_000, # step in which epsilon will be approximately epsilon_f + 0.36 * (epsilon_0 - epsilon_f)\n",
    "        verbose=False):\n",
    "    \n",
    "    model_target = deepcopy(model)\n",
    "\n",
    "    def eps_scheduler(step):\n",
    "        return epsilon_f + (epsilon_0 - epsilon_f) * math.exp(-1. * step / epsilon_decay)\n",
    "\n",
    "    replay_buffer = ReplayBuffer(replay_buffer_size, backup_fraction=0.0)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)    \n",
    "    state, _ = env.reset()\n",
    "    total_reward = 0\n",
    "    metrics = {\n",
    "        'episode_rewards': [],\n",
    "        'avg_reward': None,\n",
    "        'heatmap': Heatmap(4, 12),\n",
    "    }\n",
    "    episode_step = 0\n",
    "    truncated = False\n",
    "\n",
    "    for global_step in range(total_steps):\n",
    "        epsilon = eps_scheduler(global_step)\n",
    "\n",
    "        # observe\n",
    "        action = get_action(model, state, epsilon)\n",
    "        next_state, reward, terminated, _, _ = env.step(action)\n",
    "        replay_buffer.push(state, action, reward, next_state, terminated)\n",
    "        state = next_state\n",
    "        metrics['heatmap'].update(state)\n",
    "        total_reward += reward\n",
    "        episode_step += 1\n",
    "        if episode_step > 1000:\n",
    "            truncated = True\n",
    "        done = terminated or truncated\n",
    "\n",
    "        # update\n",
    "        if global_step > batch_size and global_step % learning_freq == 0:\n",
    "            batch = replay_buffer.sample(batch_size)\n",
    "            model = update_q_net(model, model_target, optimizer, batch, gamma)\n",
    "\n",
    "        # update target network\n",
    "        if global_step % target_update_freq == 0:\n",
    "            model_target.load_state_dict(model.state_dict())\n",
    "\n",
    "        # evaluating\n",
    "        if done:\n",
    "            metrics['episode_rewards'].append(total_reward)\n",
    "            if len(metrics['episode_rewards']) > 50:\n",
    "                metrics['avg_reward'] = torch.tensor(metrics['episode_rewards']).float().unfold(0, 50, 1).mean(1)\n",
    "                print(f'avg reward: {metrics[\"avg_reward\"][-1]}')\n",
    "            with torch.no_grad():\n",
    "                metrics['qtable'] = model(torch.arange(48))\n",
    "            print(f'current step: {global_step}, epsilon: {epsilon:.2f}')\n",
    "            evaluate(metrics)\n",
    "            total_reward = 0\n",
    "            metrics['heatmap'].clear()\n",
    "            state, _ = env.reset()\n",
    "            episode_step = 0\n",
    "            truncated = False\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinando\n",
    "\n",
    "Está tudo configurado, portanto agora podemos rodar o algoritmo!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QnetEmb(nn.Module):\n",
    "    def __init__(self, n_actions=4):\n",
    "        super().__init__()\n",
    "        self.nn = nn.Embedding(48, n_actions)\n",
    "\n",
    "    def _encode_state(self, state: int | torch.Tensor) -> torch.Tensor:\n",
    "        return torch.tensor(state).long()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self._encode_state(x)\n",
    "        x = self.nn(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg reward: -68.13999938964844\n",
      "current step: 24532, epsilon: 0.13\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m q_net \u001b[38;5;241m=\u001b[39m QnetEmb()\n\u001b[1;32m      5\u001b[0m debug_model \u001b[38;5;241m=\u001b[39m deepcopy(q_net)\n\u001b[0;32m----> 6\u001b[0m trained_q_net \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcliff_walking\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq_net\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10_000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_update_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[9], line 67\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(env, model, total_steps, replay_buffer_size, batch_size, gamma, learning_rate, learning_freq, target_update_freq, tau, epsilon_0, epsilon_f, epsilon_decay, verbose)\u001b[0m\n\u001b[1;32m     65\u001b[0m     metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mqtable\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m model(torch\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m48\u001b[39m))\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcurrent step: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mglobal_step\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, epsilon: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepsilon\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 67\u001b[0m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m total_reward \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     69\u001b[0m metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mheatmap\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mclear()\n",
      "Cell \u001b[0;32mIn[8], line 5\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(metrics, show_results)\u001b[0m\n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mclf\n\u001b[0;32m----> 5\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtitle\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTotal reward of each episode\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpisode\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      7\u001b[0m plt\u001b[38;5;241m.\u001b[39mylabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTotal reward\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/cleanrl/lib/python3.10/site-packages/matplotlib/pyplot.py:3036\u001b[0m, in \u001b[0;36mtitle\u001b[0;34m(label, fontdict, loc, pad, y, **kwargs)\u001b[0m\n\u001b[1;32m   3034\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mset_title)\n\u001b[1;32m   3035\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtitle\u001b[39m(label, fontdict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, loc\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, pad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m-> 3036\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgca\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mset_title(\n\u001b[1;32m   3037\u001b[0m         label, fontdict\u001b[38;5;241m=\u001b[39mfontdict, loc\u001b[38;5;241m=\u001b[39mloc, pad\u001b[38;5;241m=\u001b[39mpad, y\u001b[38;5;241m=\u001b[39my, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/cleanrl/lib/python3.10/site-packages/matplotlib/pyplot.py:2272\u001b[0m, in \u001b[0;36mgca\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m   2270\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Figure\u001b[38;5;241m.\u001b[39mgca)\n\u001b[1;32m   2271\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgca\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m-> 2272\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgcf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgca\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/cleanrl/lib/python3.10/site-packages/matplotlib/figure.py:1567\u001b[0m, in \u001b[0;36mFigureBase.gca\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m     _api\u001b[38;5;241m.\u001b[39mwarn_deprecated(\n\u001b[1;32m   1558\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m3.4\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1559\u001b[0m         message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCalling gca() with keyword arguments was deprecated \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maxes with non-default arguments, use plt.axes() or \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1565\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplt.subplot().\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1566\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_axstack\u001b[38;5;241m.\u001b[39mempty():\n\u001b[0;32m-> 1567\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_subplot\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1568\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1569\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_axstack()\n",
      "File \u001b[0;32m~/anaconda3/envs/cleanrl/lib/python3.10/site-packages/matplotlib/figure.py:772\u001b[0m, in \u001b[0;36mFigureBase.add_subplot\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    769\u001b[0m         args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mstr\u001b[39m(args[\u001b[38;5;241m0\u001b[39m])))\n\u001b[1;32m    770\u001b[0m     projection_class, pkw \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_projection_requirements(\n\u001b[1;32m    771\u001b[0m         \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 772\u001b[0m     ax \u001b[38;5;241m=\u001b[39m \u001b[43msubplot_class_factory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprojection_class\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    773\u001b[0m     key \u001b[38;5;241m=\u001b[39m (projection_class, pkw)\n\u001b[1;32m    774\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_axes_internal(ax, key)\n",
      "File \u001b[0;32m~/anaconda3/envs/cleanrl/lib/python3.10/site-packages/matplotlib/axes/_subplots.py:34\u001b[0m, in \u001b[0;36mSubplotBase.__init__\u001b[0;34m(self, fig, *args, **kwargs)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;03m----------\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;124;03m    Keyword arguments are passed to the Axes (sub)class constructor.\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# _axes_class is set in the subplot_class_factory\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_axes_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# This will also update the axes position.\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_subplotspec(SubplotSpec\u001b[38;5;241m.\u001b[39m_from_subplot_args(fig, args))\n",
      "File \u001b[0;32m~/anaconda3/envs/cleanrl/lib/python3.10/site-packages/matplotlib/_api/deprecation.py:459\u001b[0m, in \u001b[0;36mmake_keyword_only.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m name_idx:\n\u001b[1;32m    454\u001b[0m     warn_deprecated(\n\u001b[1;32m    455\u001b[0m         since, message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing the \u001b[39m\u001b[38;5;132;01m%(name)s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%(obj_type)s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    456\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpositionally is deprecated since Matplotlib \u001b[39m\u001b[38;5;132;01m%(since)s\u001b[39;00m\u001b[38;5;124m; the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    457\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter will become keyword-only \u001b[39m\u001b[38;5;132;01m%(removal)s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    458\u001b[0m         name\u001b[38;5;241m=\u001b[39mname, obj_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 459\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/cleanrl/lib/python3.10/site-packages/matplotlib/axes/_base.py:632\u001b[0m, in \u001b[0;36m_AxesBase.__init__\u001b[0;34m(self, fig, rect, facecolor, frameon, sharex, sharey, label, xscale, yscale, box_aspect, **kwargs)\u001b[0m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_axisbelow(mpl\u001b[38;5;241m.\u001b[39mrcParams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maxes.axisbelow\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rasterization_zorder \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 632\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcla\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;66;03m# funcs used to format x and y - fall back on major formatters\u001b[39;00m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt_xdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/cleanrl/lib/python3.10/site-packages/matplotlib/axes/_base.py:1250\u001b[0m, in \u001b[0;36m_AxesBase.cla\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1247\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlegend_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1248\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontainers \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m-> 1250\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Disable grid on init to use rcParameter\u001b[39;00m\n\u001b[1;32m   1251\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gridOn, which\u001b[38;5;241m=\u001b[39mmpl\u001b[38;5;241m.\u001b[39mrcParams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maxes.grid.which\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m   1252\u001b[0m           axis\u001b[38;5;241m=\u001b[39mmpl\u001b[38;5;241m.\u001b[39mrcParams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maxes.grid.axis\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m   1253\u001b[0m props \u001b[38;5;241m=\u001b[39m font_manager\u001b[38;5;241m.\u001b[39mFontProperties(\n\u001b[1;32m   1254\u001b[0m     size\u001b[38;5;241m=\u001b[39mmpl\u001b[38;5;241m.\u001b[39mrcParams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maxes.titlesize\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m   1255\u001b[0m     weight\u001b[38;5;241m=\u001b[39mmpl\u001b[38;5;241m.\u001b[39mrcParams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maxes.titleweight\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/envs/cleanrl/lib/python3.10/site-packages/matplotlib/_api/deprecation.py:302\u001b[0m, in \u001b[0;36mrename_parameter.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    297\u001b[0m     warn_deprecated(\n\u001b[1;32m    298\u001b[0m         since, message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mold\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m parameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m() \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    299\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas been renamed \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m since Matplotlib \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msince\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m; support \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    300\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor the old name will be dropped %(removal)s.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    301\u001b[0m     kwargs[new] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(old)\n\u001b[0;32m--> 302\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/cleanrl/lib/python3.10/site-packages/matplotlib/axes/_base.py:3237\u001b[0m, in \u001b[0;36m_AxesBase.grid\u001b[0;34m(self, visible, which, axis, **kwargs)\u001b[0m\n\u001b[1;32m   3235\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mxaxis\u001b[38;5;241m.\u001b[39mgrid(visible, which\u001b[38;5;241m=\u001b[39mwhich, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   3236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mboth\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m-> 3237\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43myaxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvisible\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhich\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhich\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/cleanrl/lib/python3.10/site-packages/matplotlib/_api/deprecation.py:302\u001b[0m, in \u001b[0;36mrename_parameter.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    297\u001b[0m     warn_deprecated(\n\u001b[1;32m    298\u001b[0m         since, message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mold\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m parameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m() \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    299\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas been renamed \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m since Matplotlib \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msince\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m; support \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    300\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor the old name will be dropped %(removal)s.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    301\u001b[0m     kwargs[new] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(old)\n\u001b[0;32m--> 302\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/cleanrl/lib/python3.10/site-packages/matplotlib/axis.py:1434\u001b[0m, in \u001b[0;36mAxis.grid\u001b[0;34m(self, visible, which, **kwargs)\u001b[0m\n\u001b[1;32m   1431\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m which \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmajor\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mboth\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m   1432\u001b[0m     gridkw[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgridOn\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_major_tick_kw[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgridOn\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m   1433\u001b[0m                         \u001b[38;5;28;01mif\u001b[39;00m visible \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m visible)\n\u001b[0;32m-> 1434\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_tick_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwhich\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmajor\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgridkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1435\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstale \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/cleanrl/lib/python3.10/site-packages/matplotlib/axis.py:873\u001b[0m, in \u001b[0;36mAxis.set_tick_params\u001b[0;34m(self, which, reset, **kw)\u001b[0m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m which \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmajor\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mboth\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m    872\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_major_tick_kw\u001b[38;5;241m.\u001b[39mupdate(kwtrans)\n\u001b[0;32m--> 873\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m tick \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmajorTicks\u001b[49m:\n\u001b[1;32m    874\u001b[0m         tick\u001b[38;5;241m.\u001b[39m_apply_params(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwtrans)\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m which \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminor\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mboth\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n",
      "File \u001b[0;32m~/anaconda3/envs/cleanrl/lib/python3.10/site-packages/matplotlib/axis.py:593\u001b[0m, in \u001b[0;36m_LazyTickList.__get__\u001b[0;34m(self, instance, cls)\u001b[0m\n\u001b[1;32m    591\u001b[0m     instance\u001b[38;5;241m.\u001b[39mmajorTicks \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    592\u001b[0m     tick \u001b[38;5;241m=\u001b[39m instance\u001b[38;5;241m.\u001b[39m_get_tick(major\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 593\u001b[0m     \u001b[43minstance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmajorTicks\u001b[49m\u001b[38;5;241m.\u001b[39mappend(tick)\n\u001b[1;32m    594\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m instance\u001b[38;5;241m.\u001b[39mmajorTicks\n\u001b[1;32m    595\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/cleanrl/lib/python3.10/site-packages/matplotlib/axis.py:592\u001b[0m, in \u001b[0;36m_LazyTickList.__get__\u001b[0;34m(self, instance, cls)\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_major:\n\u001b[1;32m    591\u001b[0m     instance\u001b[38;5;241m.\u001b[39mmajorTicks \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 592\u001b[0m     tick \u001b[38;5;241m=\u001b[39m \u001b[43minstance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_tick\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmajor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    593\u001b[0m     instance\u001b[38;5;241m.\u001b[39mmajorTicks\u001b[38;5;241m.\u001b[39mappend(tick)\n\u001b[1;32m    594\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m instance\u001b[38;5;241m.\u001b[39mmajorTicks\n",
      "File \u001b[0;32m~/anaconda3/envs/cleanrl/lib/python3.10/site-packages/matplotlib/axis.py:2322\u001b[0m, in \u001b[0;36mYAxis._get_tick\u001b[0;34m(self, major)\u001b[0m\n\u001b[1;32m   2320\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2321\u001b[0m     tick_kw \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_minor_tick_kw\n\u001b[0;32m-> 2322\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mYTick\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmajor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmajor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtick_kw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/cleanrl/lib/python3.10/site-packages/matplotlib/axis.py:476\u001b[0m, in \u001b[0;36mYTick.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 476\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    477\u001b[0m     \u001b[38;5;66;03m# x in axes coords, y in data coords\u001b[39;00m\n\u001b[1;32m    478\u001b[0m     ax \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes\n",
      "File \u001b[0;32m~/anaconda3/envs/cleanrl/lib/python3.10/site-packages/matplotlib/axis.py:160\u001b[0m, in \u001b[0;36mTick.__init__\u001b[0;34m(self, axes, loc, size, width, color, tickdir, pad, labelsize, labelcolor, zorder, gridOn, tick1On, tick2On, label1On, label2On, major, labelrotation, grid_color, grid_linestyle, grid_linewidth, grid_alpha, **kw)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtick1line \u001b[38;5;241m=\u001b[39m mlines\u001b[38;5;241m.\u001b[39mLine2D(\n\u001b[1;32m    151\u001b[0m     [], [],\n\u001b[1;32m    152\u001b[0m     color\u001b[38;5;241m=\u001b[39mcolor, linestyle\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m\"\u001b[39m, zorder\u001b[38;5;241m=\u001b[39mzorder, visible\u001b[38;5;241m=\u001b[39mtick1On,\n\u001b[1;32m    153\u001b[0m     markeredgecolor\u001b[38;5;241m=\u001b[39mcolor, markersize\u001b[38;5;241m=\u001b[39msize, markeredgewidth\u001b[38;5;241m=\u001b[39mwidth,\n\u001b[1;32m    154\u001b[0m )\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtick2line \u001b[38;5;241m=\u001b[39m mlines\u001b[38;5;241m.\u001b[39mLine2D(\n\u001b[1;32m    156\u001b[0m     [], [],\n\u001b[1;32m    157\u001b[0m     color\u001b[38;5;241m=\u001b[39mcolor, linestyle\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m\"\u001b[39m, zorder\u001b[38;5;241m=\u001b[39mzorder, visible\u001b[38;5;241m=\u001b[39mtick2On,\n\u001b[1;32m    158\u001b[0m     markeredgecolor\u001b[38;5;241m=\u001b[39mcolor, markersize\u001b[38;5;241m=\u001b[39msize, markeredgewidth\u001b[38;5;241m=\u001b[39mwidth,\n\u001b[1;32m    159\u001b[0m )\n\u001b[0;32m--> 160\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgridline \u001b[38;5;241m=\u001b[39m \u001b[43mmlines\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLine2D\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrid_color\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrid_alpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisible\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgridOn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlinestyle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrid_linestyle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlinewidth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrid_linewidth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmarker\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgrid_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgridline\u001b[38;5;241m.\u001b[39mget_path()\u001b[38;5;241m.\u001b[39m_interpolation_steps \u001b[38;5;241m=\u001b[39m \\\n\u001b[1;32m    167\u001b[0m     GRIDLINE_INTERPOLATION_STEPS\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel1 \u001b[38;5;241m=\u001b[39m mtext\u001b[38;5;241m.\u001b[39mText(\n\u001b[1;32m    169\u001b[0m     np\u001b[38;5;241m.\u001b[39mnan, np\u001b[38;5;241m.\u001b[39mnan,\n\u001b[1;32m    170\u001b[0m     fontsize\u001b[38;5;241m=\u001b[39mlabelsize, color\u001b[38;5;241m=\u001b[39mlabelcolor, visible\u001b[38;5;241m=\u001b[39mlabel1On,\n\u001b[1;32m    171\u001b[0m     rotation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_labelrotation[\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/envs/cleanrl/lib/python3.10/site-packages/matplotlib/lines.py:350\u001b[0m, in \u001b[0;36mLine2D.__init__\u001b[0;34m(self, xdata, ydata, linewidth, linestyle, color, marker, markersize, markeredgewidth, markeredgecolor, markerfacecolor, markerfacecoloralt, fillstyle, antialiased, dash_capstyle, solid_capstyle, dash_joinstyle, solid_joinstyle, pickradius, drawstyle, markevery, **kwargs)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_dash_capstyle(dash_capstyle)\n\u001b[1;32m    349\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_dash_joinstyle(dash_joinstyle)\n\u001b[0;32m--> 350\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_solid_capstyle\u001b[49m\u001b[43m(\u001b[49m\u001b[43msolid_capstyle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_solid_joinstyle(solid_joinstyle)\n\u001b[1;32m    353\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_linestyles \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/cleanrl/lib/python3.10/site-packages/matplotlib/lines.py:1366\u001b[0m, in \u001b[0;36mLine2D.set_solid_capstyle\u001b[0;34m(self, s)\u001b[0m\n\u001b[1;32m   1355\u001b[0m \u001b[38;5;129m@docstring\u001b[39m\u001b[38;5;241m.\u001b[39minterpd\n\u001b[1;32m   1356\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset_solid_capstyle\u001b[39m(\u001b[38;5;28mself\u001b[39m, s):\n\u001b[1;32m   1357\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1358\u001b[0m \u001b[38;5;124;03m    How to draw the end caps if the line is solid (not `~Line2D.is_dashed`)\u001b[39;00m\n\u001b[1;32m   1359\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1364\u001b[0m \u001b[38;5;124;03m    s : `.CapStyle` or %(CapStyle)s\u001b[39;00m\n\u001b[1;32m   1365\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1366\u001b[0m     cs \u001b[38;5;241m=\u001b[39m \u001b[43mCapStyle\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1367\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_solidcapstyle \u001b[38;5;241m!=\u001b[39m cs:\n\u001b[1;32m   1368\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstale \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/cleanrl/lib/python3.10/enum.py:385\u001b[0m, in \u001b[0;36mEnumMeta.__call__\u001b[0;34m(cls, value, names, module, qualname, type, start)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;124;03mEither returns an existing member, or creates a new enum class.\u001b[39;00m\n\u001b[1;32m    362\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;124;03m`type`, if set, will be mixed in as the first base class.\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    384\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# simple value lookup\u001b[39;00m\n\u001b[0;32m--> 385\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__new__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;66;03m# otherwise, functional API: we're creating a new Enum type\u001b[39;00m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_create_(\n\u001b[1;32m    388\u001b[0m         value,\n\u001b[1;32m    389\u001b[0m         names,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    393\u001b[0m         start\u001b[38;5;241m=\u001b[39mstart,\n\u001b[1;32m    394\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/envs/cleanrl/lib/python3.10/enum.py:678\u001b[0m, in \u001b[0;36mEnum.__new__\u001b[0;34m(cls, value)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mEnum\u001b[39;00m(metaclass\u001b[38;5;241m=\u001b[39mEnumMeta):\n\u001b[1;32m    673\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    674\u001b[0m \u001b[38;5;124;03m    Generic enumeration.\u001b[39;00m\n\u001b[1;32m    675\u001b[0m \n\u001b[1;32m    676\u001b[0m \u001b[38;5;124;03m    Derive from this class to define new enumerations.\u001b[39;00m\n\u001b[1;32m    677\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 678\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__new__\u001b[39m(\u001b[38;5;28mcls\u001b[39m, value):\n\u001b[1;32m    679\u001b[0m         \u001b[38;5;66;03m# all enum instances are actually created during class construction\u001b[39;00m\n\u001b[1;32m    680\u001b[0m         \u001b[38;5;66;03m# without calling this method; this method is called by the metaclass'\u001b[39;00m\n\u001b[1;32m    681\u001b[0m         \u001b[38;5;66;03m# __call__ (i.e. Color(3) ), and by pickle\u001b[39;00m\n\u001b[1;32m    682\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(value) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mcls\u001b[39m:\n\u001b[1;32m    683\u001b[0m             \u001b[38;5;66;03m# For lookups like Color(Color.RED)\u001b[39;00m\n\u001b[1;32m    684\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m value\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "random.seed(0)\n",
    "cliff_walking = gym.make('CliffWalking-v0')\n",
    "q_net = QnetEmb()\n",
    "debug_model = deepcopy(q_net)\n",
    "trained_q_net = train(cliff_walking, q_net, epsilon_decay=10_000, learning_rate=1e-3, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testando o agente\n",
    "\n",
    "A função abaixo rodará um episódio com o agente já treinado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(env: gym.Env, \n",
    "          q_net,\n",
    "          n_episodes=1,\n",
    "          verbose=False\n",
    "          ):\n",
    "    \n",
    "    total_rewards = []\n",
    "    for episode in range(n_episodes):\n",
    "        state, _ = env.reset()\n",
    "        total_reward = 0\n",
    "        done = False\n",
    "        \n",
    "        while not done:\n",
    "            action = get_action(q_net, state, 0)\n",
    "            state, reward, terminated, truncated, _ = env.step(action)\n",
    "            total_reward += reward\n",
    "\n",
    "            done = terminated or truncated\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Episode {episode} - Total reward: {total_reward}\")\n",
    "            \n",
    "        total_rewards.append(total_reward)\n",
    "\n",
    "    env.close()\n",
    "    return torch.mean(total_reward)\n",
    "\n",
    "#test(gym.make('CliffWalking-v0', render_mode=\"human\"), trained_q_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise de resultados\n",
    "\n",
    "### Visualizando a política\n",
    "\n",
    "A célula abaixo permitirá observar a ação mais provável de ser tomada em cada uma das posições do tabuleiro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24739/1860028285.py:20: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  y = (state // 12) / 3\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m reload(plots)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mplots\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot_arrows_from_qnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdebug_model\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/rl_practice_eldorado/utils/plots_cliffwalking.py:64\u001b[0m, in \u001b[0;36mplot_arrows_from_qnet\u001b[0;34m(q_net)\u001b[0m\n\u001b[1;32m     61\u001b[0m normalized_q_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.4\u001b[39m \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39msoftmax(qvals\u001b[38;5;241m/\u001b[39mT, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# cima\u001b[39;00m\n\u001b[0;32m---> 64\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalized_q_values\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhead_width\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhead_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mec\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# direita\u001b[39;00m\n\u001b[1;32m     66\u001b[0m plt\u001b[38;5;241m.\u001b[39marrow(x, y, normalized_q_values[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;241m0\u001b[39m, head_width\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, head_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, fc\u001b[38;5;241m=\u001b[39ma, ec\u001b[38;5;241m=\u001b[39ma)\n",
      "File \u001b[0;32m~/anaconda3/envs/cleanrl/lib/python3.10/site-packages/matplotlib/pyplot.py:2347\u001b[0m, in \u001b[0;36marrow\u001b[0;34m(x, y, dx, dy, **kwargs)\u001b[0m\n\u001b[1;32m   2345\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39marrow)\n\u001b[1;32m   2346\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21marrow\u001b[39m(x, y, dx, dy, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m-> 2347\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgca\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/cleanrl/lib/python3.10/site-packages/matplotlib/axes/_axes.py:4961\u001b[0m, in \u001b[0;36mAxes.arrow\u001b[0;34m(self, x, y, dx, dy, **kwargs)\u001b[0m\n\u001b[1;32m   4958\u001b[0m dx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_xunits(dx)\n\u001b[1;32m   4959\u001b[0m dy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_yunits(dy)\n\u001b[0;32m-> 4961\u001b[0m a \u001b[38;5;241m=\u001b[39m \u001b[43mmpatches\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFancyArrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4962\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_patch(a)\n\u001b[1;32m   4963\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request_autoscale_view()\n",
      "File \u001b[0;32m~/anaconda3/envs/cleanrl/lib/python3.10/site-packages/matplotlib/patches.py:1350\u001b[0m, in \u001b[0;36mFancyArrow.__init__\u001b[0;34m(self, x, y, dx, dy, width, length_includes_head, head_width, head_length, shape, overhang, head_starts_at_zero, **kwargs)\u001b[0m\n\u001b[1;32m   1348\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_overhang \u001b[38;5;241m=\u001b[39m overhang\n\u001b[1;32m   1349\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_head_starts_at_zero \u001b[38;5;241m=\u001b[39m head_starts_at_zero\n\u001b[0;32m-> 1350\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_verts\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1351\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverts, closed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/cleanrl/lib/python3.10/site-packages/matplotlib/patches.py:1409\u001b[0m, in \u001b[0;36mFancyArrow._make_verts\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1407\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1408\u001b[0m     length \u001b[38;5;241m=\u001b[39m distance \u001b[38;5;241m+\u001b[39m head_length\n\u001b[0;32m-> 1409\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m length:\n\u001b[1;32m   1410\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverts \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty([\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m])  \u001b[38;5;66;03m# display nothing if empty\u001b[39;00m\n\u001b[1;32m   1411\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1412\u001b[0m     \u001b[38;5;66;03m# start by drawing horizontal arrow, point at (0, 0)\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "reload(plots)\n",
    "plots.plot_arrows_from_qnet(debug_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lunar_lander",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
